{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8695193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c4a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('DataSet_Total_Walsh.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36272753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.177237</td>\n",
       "      <td>0.099807</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>1.564971</td>\n",
       "      <td>-3.426974</td>\n",
       "      <td>-0.701468</td>\n",
       "      <td>0.664442</td>\n",
       "      <td>-1.415147</td>\n",
       "      <td>-1.048870</td>\n",
       "      <td>-0.387557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796155</td>\n",
       "      <td>-0.035896</td>\n",
       "      <td>-0.476052</td>\n",
       "      <td>-0.233128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.227044</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.211965</td>\n",
       "      <td>1.189603</td>\n",
       "      <td>-3.436533</td>\n",
       "      <td>0.012993</td>\n",
       "      <td>0.433340</td>\n",
       "      <td>-1.663144</td>\n",
       "      <td>-1.222274</td>\n",
       "      <td>0.090048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202891</td>\n",
       "      <td>-0.217979</td>\n",
       "      <td>-0.221793</td>\n",
       "      <td>0.066452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.204134</td>\n",
       "      <td>-0.081315</td>\n",
       "      <td>0.241718</td>\n",
       "      <td>4.302551</td>\n",
       "      <td>-4.435533</td>\n",
       "      <td>-1.315352</td>\n",
       "      <td>0.124246</td>\n",
       "      <td>-2.784308</td>\n",
       "      <td>-1.944363</td>\n",
       "      <td>-0.534279</td>\n",
       "      <td>...</td>\n",
       "      <td>2.709597</td>\n",
       "      <td>0.445616</td>\n",
       "      <td>-0.775808</td>\n",
       "      <td>0.274888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.218254</td>\n",
       "      <td>-0.043448</td>\n",
       "      <td>0.238516</td>\n",
       "      <td>3.058132</td>\n",
       "      <td>-4.066913</td>\n",
       "      <td>-0.318107</td>\n",
       "      <td>0.404549</td>\n",
       "      <td>-2.426833</td>\n",
       "      <td>-1.486463</td>\n",
       "      <td>-0.308362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708945</td>\n",
       "      <td>0.200189</td>\n",
       "      <td>-0.347463</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.153955</td>\n",
       "      <td>-0.189749</td>\n",
       "      <td>0.240992</td>\n",
       "      <td>8.871455</td>\n",
       "      <td>-2.073549</td>\n",
       "      <td>-1.002858</td>\n",
       "      <td>0.253458</td>\n",
       "      <td>-4.489565</td>\n",
       "      <td>-0.735555</td>\n",
       "      <td>-0.508349</td>\n",
       "      <td>...</td>\n",
       "      <td>3.147622</td>\n",
       "      <td>0.846095</td>\n",
       "      <td>-0.810594</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.177237  0.099807  0.115007  1.564971 -3.426974 -0.701468  0.664442   \n",
       "1 -0.227044  0.079490  0.211965  1.189603 -3.436533  0.012993  0.433340   \n",
       "2 -0.204134 -0.081315  0.241718  4.302551 -4.435533 -1.315352  0.124246   \n",
       "3 -0.218254 -0.043448  0.238516  3.058132 -4.066913 -0.318107  0.404549   \n",
       "4 -0.153955 -0.189749  0.240992  8.871455 -2.073549 -1.002858  0.253458   \n",
       "\n",
       "         7         8         9   ...        26        27        28        29  \\\n",
       "0 -1.415147 -1.048870 -0.387557  ...  0.796155 -0.035896 -0.476052 -0.233128   \n",
       "1 -1.663144 -1.222274  0.090048  ...  1.202891 -0.217979 -0.221793  0.066452   \n",
       "2 -2.784308 -1.944363 -0.534279  ...  2.709597  0.445616 -0.775808  0.274888   \n",
       "3 -2.426833 -1.486463 -0.308362  ...  1.708945  0.200189 -0.347463 -0.009817   \n",
       "4 -4.489565 -0.735555 -0.508349  ...  3.147622  0.846095 -0.810594  0.994890   \n",
       "\n",
       "    30   31   32   33   34   35  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data['dados'])\n",
    "df.head()\n",
    "# features: 0->29 30-features\n",
    "# labels: 30 -> 35 6-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c43d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform Train/Test/Split\n",
    "X = df.drop([30,31,32,33,34,35],axis=1).values\n",
    "y = df[[30,31,32,33,34,35]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2c7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=33, shuffle = True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.20,random_state=33, shuffle = True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train).cuda()\n",
    "X_test = torch.FloatTensor(X_test).cuda()\n",
    "X_val = torch.FloatTensor(X_val).cuda()\n",
    "#y_train = torch.FloatTensor(y_train).cuda()\n",
    "#y_test = torch.FloatTensor(y_test).cuda()\n",
    "\n",
    "y_val = torch.LongTensor(y_val).cuda()\n",
    "y_train = torch.LongTensor(y_train).cuda()\n",
    "y_test = torch.LongTensor(y_test).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703d710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=30, h1=100, h2=50, out_features=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # input layer -> 1 hidden -> 2 hidden -> output \n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the neuron input through its activation function to obtain the output of the neuron\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c10317",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "model = Model().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c3a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 1.79269266\n",
      "epoch: 101  loss: 0.70871848\n",
      "epoch: 201  loss: 0.32661030\n",
      "epoch: 301  loss: 0.20047401\n",
      "epoch: 401  loss: 0.14123903\n",
      "epoch: 501  loss: 0.10857904\n",
      "epoch: 601  loss: 0.08948430\n",
      "epoch: 701  loss: 0.07470568\n",
      "epoch: 801  loss: 0.06552012\n",
      "epoch: 901  loss: 0.05650461\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000 # number of runs through the training data\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred,torch.max(y_train, 1)[1] )\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%100 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad() #zero-grad to not accomulate the gradient over the epochs\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b98cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 1, 2,  ..., 5, 1, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "Test_Predictions = torch.max(y_pred,1)[1]\n",
    "print(Test_Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e42318",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00ab19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_pred = model.forward(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5168b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = torch.max(y_val_pred,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f3b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1862    8    5    4    4    2]\n",
      " [   9 1806    2    0    6    2]\n",
      " [   0    0 1809    6    0    1]\n",
      " [   2    1    9 1849    9    7]\n",
      " [   3    6   17   12 1866    3]\n",
      " [  10    8    5   14    0 1850]]\n"
     ]
    }
   ],
   "source": [
    "y_val = y_val.cpu().numpy()\n",
    "y_val_pred = y_val_pred.cpu().numpy()\n",
    "y_val = np.argmax(y_val, axis=1) # assuming you have n-by-5 class_prob\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7db8b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1885\n",
      "           1       0.99      0.99      0.99      1825\n",
      "           2       0.98      1.00      0.99      1816\n",
      "           3       0.98      0.99      0.98      1877\n",
      "           4       0.99      0.98      0.98      1907\n",
      "           5       0.99      0.98      0.99      1887\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     11197\n",
      "   macro avg       0.99      0.99      0.99     11197\n",
      "weighted avg       0.99      0.99      0.99     11197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18d4f6",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13850be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddce8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = torch.max(y_test_pred,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15cb264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2296    9    8    3    4    2]\n",
      " [  17 2318    9    3   15    6]\n",
      " [   0    0 2386    5    0    0]\n",
      " [   2    0    8 2348    7    6]\n",
      " [   9   11   15    7 2167    6]\n",
      " [   6    5    5   19    0 2294]]\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.cpu().numpy()\n",
    "y_test_pred = y_test_pred.cpu().numpy()\n",
    "y_test = np.argmax(y_test, axis=1) # assuming you have n-by-5 class_prob\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f552171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2322\n",
      "           1       0.99      0.98      0.98      2368\n",
      "           2       0.98      1.00      0.99      2391\n",
      "           3       0.98      0.99      0.99      2371\n",
      "           4       0.99      0.98      0.98      2215\n",
      "           5       0.99      0.98      0.99      2329\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     13996\n",
      "   macro avg       0.99      0.99      0.99     13996\n",
      "weighted avg       0.99      0.99      0.99     13996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bd8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
