{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].replace(['M', 'B'], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BigOrSmall'] = np.where(df['area_mean']>555, 'Big', 'Small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>BigOrSmall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>Big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>Big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>Big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>Big</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0         0.2419  ...          17.33           184.60      2019.0   \n",
       "1         0.1812  ...          23.41           158.80      1956.0   \n",
       "2         0.2069  ...          25.53           152.50      1709.0   \n",
       "3         0.2597  ...          26.50            98.87       567.7   \n",
       "4         0.1809  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  BigOrSmall  \n",
       "0          0.4601                  0.11890         Big  \n",
       "1          0.2750                  0.08902         Big  \n",
       "2          0.3613                  0.08758         Big  \n",
       "3          0.6638                  0.17300       Small  \n",
       "4          0.2364                  0.07678         Big  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'BigOrSmall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['diagnosis', 'radius_mean', 'texture_mean','BigOrSmall', 'smoothness_mean', 'texture_se', 'texture_worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>BigOrSmall</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>texture_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>Big</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>Big</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>23.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>Big</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>25.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>Big</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean BigOrSmall  smoothness_mean  \\\n",
       "0          1        17.99         10.38        Big          0.11840   \n",
       "1          1        20.57         17.77        Big          0.08474   \n",
       "2          1        19.69         21.25        Big          0.10960   \n",
       "3          1        11.42         20.38      Small          0.14250   \n",
       "4          1        20.29         14.34        Big          0.10030   \n",
       "\n",
       "   texture_se  texture_worst  \n",
       "0      0.9053          17.33  \n",
       "1      0.7339          23.41  \n",
       "2      0.7869          25.53  \n",
       "3      1.1560          26.50  \n",
       "4      0.7813          16.67  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the diagnosis. And we introduced a new categorical feature BigOrSmall. It will use a reduced dataframe as it is seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Divide into categorical e continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['BigOrSmall']\n",
    "cont_cols = ['radius_mean', 'texture_mean', 'smoothness_mean', 'texture_se', 'texture_worst']\n",
    "y_col = ['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Assign the Categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Big\n",
       "1      Big\n",
       "2      Big\n",
       "3    Small\n",
       "4      Big\n",
       "Name: BigOrSmall, dtype: category\n",
       "Categories (2, object): ['Big', 'Small']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BigOrSmall'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Stack into an array the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = df['BigOrSmall'].cat.codes.values\n",
    "cats = np.stack([BS], 1)\n",
    "\n",
    "# Convert to tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Stack into an array the continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "\n",
    "# Convert to tensor\n",
    "conts = torch.tensor(conts, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Create Label Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df[y_col].values).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Embedding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Train and test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "b = 569# suggested batch size\n",
    "t = 300  # suggested test size\n",
    "\n",
    "cat_train = cats[:b-t]\n",
    "cat_test = cats[b-t:b]\n",
    "con_train = conts[:b-t]\n",
    "con_test = conts[b-t:b]\n",
    "y_train = y[:b-t]\n",
    "y_test = y[b-t:b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Tabular Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Instanciate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(emb_szs, conts.shape[1], 2, [50, 20], p=0.65) # out_sz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.65, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.65, inplace=False)\n",
       "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.65, inplace=False)\n",
       "    (8): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Define Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.82527632\n",
      "epoch:  26  loss: 0.53958052\n",
      "epoch:  51  loss: 0.49031311\n",
      "epoch:  76  loss: 0.36736631\n",
      "epoch: 101  loss: 0.28193927\n",
      "epoch: 126  loss: 0.27715251\n",
      "epoch: 151  loss: 0.26507416\n",
      "epoch: 176  loss: 0.22014228\n",
      "epoch: 201  loss: 0.21375619\n",
      "epoch: 226  loss: 0.17763563\n",
      "epoch: 251  loss: 0.17699653\n",
      "epoch: 276  loss: 0.17265297\n",
      "epoch: 300  loss: 0.18977384\n",
      "\n",
      "Duration: 2 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Plot the Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1898, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "plt.plot(range(epochs),losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');\n",
    "print(losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.67494678\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val = model(cat_test,con_test)\n",
    "    loss = criterion(y_val,y_test)\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets obtain the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([ 2.3360, -0.5690])    0      0   \n",
      "tensor([ 4.2680, -2.0070])    0      0   \n",
      "tensor([ 2.5722, -5.9588])    0      0   \n",
      "tensor([-2.4543,  3.2955])    1      1   \n",
      "tensor([  5.1016, -10.2323])    0      0   \n",
      "tensor([-3.4690,  1.6169])    1      1   \n",
      "tensor([ 1.7432, -2.3684])    0      0   \n",
      "tensor([ 1.6082, -2.1396])    0      0   \n",
      "tensor([-4.0682,  1.9223])    1      1   \n",
      "tensor([0.2699, 1.1710])      1      0   \n",
      "tensor([-0.3228,  1.1777])    1      0   \n",
      "tensor([-3.2891,  1.8991])    1      1   \n",
      "tensor([ 3.3507, -3.3620])    0      0   \n",
      "tensor([-3.8901,  2.0883])    1      1   \n",
      "tensor([-1.6349,  1.4571])    1      1   \n",
      "tensor([ 1.1770, -0.8714])    0      0   \n",
      "tensor([ 2.9277, -3.9986])    0      0   \n",
      "tensor([ 1.6590, -0.5759])    0      0   \n",
      "tensor([ 0.7578, -1.0583])    0      0   \n",
      "tensor([ 4.4131, -3.1266])    0      0   \n",
      "tensor([ 3.0584, -2.9737])    0      0   \n",
      "tensor([ 0.7703, -0.3200])    0      0   \n",
      "tensor([-1.6683,  1.2470])    1      0   \n",
      "tensor([ 1.4144, -0.7071])    0      0   \n",
      "tensor([ 0.9321, -0.5675])    0      0   \n",
      "tensor([ 3.2933, -2.6096])    0      0   \n",
      "tensor([ 2.9525, -5.3868])    0      0   \n",
      "tensor([ 3.1448, -2.6280])    0      0   \n",
      "tensor([ 2.4446, -1.1568])    0      1   \n",
      "tensor([-0.0367, -0.0693])    0      0   \n",
      "tensor([ 0.8496, -0.9012])    0      0   \n",
      "tensor([-3.8346,  3.1508])    1      1   \n",
      "tensor([0.2958, 0.3796])      1      0   \n",
      "tensor([-4.6787,  3.8198])    1      1   \n",
      "tensor([ 1.5296, -1.0664])    0      0   \n",
      "tensor([ 2.2080, -1.9530])    0      0   \n",
      "tensor([-0.6333,  0.4397])    1      0   \n",
      "tensor([ 0.8994, -0.6423])    0      0   \n",
      "tensor([ 2.4532, -3.8675])    0      0   \n",
      "tensor([ 2.3649, -4.2027])    0      0   \n",
      "tensor([ 2.2936, -4.5560])    0      0   \n",
      "tensor([ 2.6071, -2.2041])    0      0   \n",
      "tensor([ 2.6406, -2.5868])    0      0   \n",
      "tensor([ 1.8241, -2.1338])    0      0   \n",
      "tensor([ 3.9551, -1.4633])    0      0   \n",
      "tensor([ 2.7001, -0.2500])    0      0   \n",
      "tensor([ 2.2099, -0.6045])    0      0   \n",
      "tensor([ 1.1609, -2.3699])    0      0   \n",
      "tensor([-9.8091,  1.1032])    1      1   \n",
      "tensor([ 2.4359, -3.8716])    0      0   \n",
      "tensor([ 1.0978, -2.2468])    0      0   \n",
      "tensor([ 2.7128, -1.6810])    0      0   \n",
      "tensor([-2.6686,  0.7459])    1      1   \n",
      "tensor([-1.3103,  1.4814])    1      0   \n",
      "tensor([-7.6712,  7.5691])    1      1   \n",
      "tensor([ 0.8168, -1.1360])    0      0   \n",
      "tensor([-0.0024,  0.8661])    1      0   \n",
      "tensor([ 1.2344, -2.4890])    0      0   \n",
      "tensor([ 3.7379, -4.1052])    0      0   \n",
      "tensor([-0.9990,  2.5719])    1      1   \n",
      "tensor([-0.7282,  3.2871])    1      1   \n",
      "tensor([-1.5845,  1.6896])    1      1   \n",
      "tensor([ 0.6969, -0.9438])    0      0   \n",
      "tensor([ 0.1499, -0.5273])    0      0   \n",
      "tensor([ 4.9024, -2.7246])    0      0   \n",
      "tensor([ 1.2510, -0.3041])    0      0   \n",
      "tensor([-4.6858,  3.2349])    1      1   \n",
      "tensor([ 1.3000, -1.5313])    0      0   \n",
      "tensor([-3.2824,  3.6582])    1      1   \n",
      "tensor([ 3.7353, -1.8311])    0      0   \n",
      "tensor([-3.3034,  1.3293])    1      1   \n",
      "tensor([-0.1727,  1.2642])    1      0   \n",
      "tensor([ 3.2301, -4.1023])    0      0   \n",
      "tensor([ 3.0024, -1.4887])    0      0   \n",
      "tensor([-1.5861,  1.9800])    1      1   \n",
      "tensor([ 0.9030, -0.6106])    0      0   \n",
      "tensor([ 6.9898, -7.4644])    0      0   \n",
      "tensor([ 0.3174, -0.1037])    0      0   \n",
      "tensor([-1.2783,  3.0073])    1      0   \n",
      "tensor([ 3.7538, -3.0053])    0      0   \n",
      "tensor([1.0342, 0.6500])      0      0   \n",
      "tensor([ 1.1910, -3.1976])    0      0   \n",
      "tensor([-3.4576,  3.5884])    1      1   \n",
      "tensor([-2.9026,  5.3641])    1      1   \n",
      "tensor([-1.0042,  0.8958])    1      1   \n",
      "tensor([ 3.6618, -1.2542])    0      0   \n",
      "tensor([ 1.3053, -2.6118])    0      0   \n",
      "tensor([-0.2909,  0.7270])    1      0   \n",
      "tensor([-0.1886,  0.1818])    1      0   \n",
      "tensor([ 5.1332, -5.9513])    0      0   \n",
      "tensor([ 0.9662, -2.2698])    0      0   \n",
      "tensor([1.1190, 0.7203])      0      0   \n",
      "tensor([0.1794, 0.0325])      0      0   \n",
      "tensor([-2.1386,  1.5790])    1      0   \n",
      "tensor([-3.3379,  3.0597])    1      0   \n",
      "tensor([ 1.6592, -0.7920])    0      0   \n",
      "tensor([-7.1366,  5.0808])    1      1   \n",
      "tensor([-4.6860,  2.1985])    1      1   \n",
      "tensor([ 1.4915, -1.3676])    0      0   \n",
      "tensor([-5.2435,  1.8899])    1      1   \n",
      "tensor([-9.3655,  3.4133])    1      1   \n",
      "tensor([-2.0674,  1.6379])    1      1   \n",
      "tensor([ 0.7461, -0.7124])    0      0   \n",
      "tensor([-3.2658,  1.3960])    1      1   \n",
      "tensor([-1.9990,  2.0678])    1      1   \n",
      "tensor([ 1.2491, -0.6676])    0      0   \n",
      "tensor([-1.6231,  1.3305])    1      0   \n",
      "tensor([ 1.2074, -1.5975])    0      0   \n",
      "tensor([-0.0755,  2.1172])    1      0   \n",
      "tensor([0.6569, 0.1546])      0      0   \n",
      "tensor([-4.8203,  1.8295])    1      1   \n",
      "tensor([-0.5821, -1.0180])    0      0   \n",
      "tensor([ 3.0613, -3.4539])    0      0   \n",
      "tensor([ 4.5343, -1.0581])    0      0   \n",
      "tensor([ 0.1957, -0.3675])    0      0   \n",
      "tensor([ 3.4293, -3.2485])    0      0   \n",
      "tensor([-2.4834,  2.0279])    1      1   \n",
      "tensor([ 3.0840, -3.9300])    0      0   \n",
      "tensor([ 3.2305, -1.2693])    0      0   \n",
      "tensor([ 2.2910, -4.9775])    0      0   \n",
      "tensor([-4.7454,  5.0716])    1      1   \n",
      "tensor([ 3.1898, -3.6496])    0      0   \n",
      "tensor([ 2.8270, -6.2458])    0      0   \n",
      "tensor([-3.5898,  3.1504])    1      1   \n",
      "tensor([-3.1178,  2.2182])    1      1   \n",
      "tensor([0.3077, 0.5251])      1      0   \n",
      "tensor([-0.1972,  1.3636])    1      0   \n",
      "tensor([-1.8652,  1.3458])    1      0   \n",
      "tensor([ 1.9684, -1.5284])    0      0   \n",
      "tensor([ 2.7863, -2.7676])    0      0   \n",
      "tensor([0.4333, 0.0398])      0      0   \n",
      "tensor([-6.4109,  4.6129])    1      1   \n",
      "tensor([ 1.3010, -1.1536])    0      0   \n",
      "tensor([ 0.2818, -0.5459])    0      0   \n",
      "tensor([-0.8025,  0.5504])    1      0   \n",
      "tensor([ 0.7076, -0.6236])    0      0   \n",
      "tensor([ 1.4493, -1.3453])    0      0   \n",
      "tensor([-1.1286,  1.9461])    1      0   \n",
      "tensor([ 3.1438, -1.9241])    0      0   \n",
      "tensor([-4.1817,  2.5365])    1      1   \n",
      "tensor([ 1.2858, -0.5175])    0      0   \n",
      "tensor([-0.9709,  1.7510])    1      0   \n",
      "tensor([ 1.8085, -0.7966])    0      0   \n",
      "tensor([ 2.4738, -2.0470])    0      0   \n",
      "tensor([-1.4542,  2.5624])    1      0   \n",
      "tensor([-2.0103,  2.3998])    1      1   \n",
      "tensor([ 0.5664, -0.5895])    0      0   \n",
      "tensor([ 3.8279, -0.9981])    0      0   \n",
      "tensor([-2.0176,  2.9323])    1      1   \n",
      "tensor([ 1.3420, -0.3670])    0      0   \n",
      "tensor([-0.7321,  0.7463])    1      0   \n",
      "tensor([ 0.3908, -1.6945])    0      0   \n",
      "tensor([-0.5353,  1.6677])    1      0   \n",
      "tensor([ 2.3978, -0.9568])    0      0   \n",
      "tensor([ 0.3377, -0.3043])    0      0   \n",
      "tensor([ 4.7988, -5.0331])    0      0   \n",
      "tensor([ 2.3364, -1.6529])    0      0   \n",
      "tensor([ 1.3108, -1.7752])    0      0   \n",
      "tensor([-0.3464,  0.1297])    1      0   \n",
      "tensor([ 5.3062, -2.7758])    0      0   \n",
      "tensor([ 3.1479, -1.7195])    0      0   \n",
      "tensor([-1.5988,  1.6805])    1      1   \n",
      "tensor([0.0278, 0.3125])      1      0   \n",
      "tensor([-7.8126,  5.2290])    1      1   \n",
      "tensor([-4.6470,  3.0805])    1      1   \n",
      "tensor([-0.3225,  0.4685])    1      0   \n",
      "tensor([-4.6370,  5.5649])    1      1   \n",
      "tensor([-0.0803,  0.1125])    1      0   \n",
      "tensor([ 0.9516, -0.6972])    0      0   \n",
      "tensor([-0.9079,  1.2106])    1      0   \n",
      "tensor([0.0481, 0.0868])      1      0   \n",
      "tensor([ 2.4143, -1.9444])    0      0   \n",
      "tensor([-1.7692,  1.7357])    1      1   \n",
      "tensor([ 2.0401, -3.3679])    0      0   \n",
      "tensor([ 2.8366, -8.1432])    0      0   \n",
      "tensor([-4.3378,  3.3340])    1      1   \n",
      "tensor([-0.9010,  0.8050])    1      0   \n",
      "tensor([-3.1581,  2.0328])    1      1   \n",
      "tensor([-3.4497,  2.9226])    1      0   \n",
      "tensor([-1.8765,  1.6945])    1      0   \n",
      "tensor([-9.1430,  3.5683])    1      1   \n",
      "tensor([ 2.6320, -5.5697])    0      0   \n",
      "tensor([-5.0667,  4.1292])    1      1   \n",
      "tensor([-0.2768, -0.2633])    1      0   \n",
      "tensor([1.1953, 0.3730])      0      0   \n",
      "tensor([ 1.2648, -0.0446])    0      0   \n",
      "tensor([-1.1274,  1.6467])    1      0   \n",
      "tensor([-0.1878, -0.4713])    0      0   \n",
      "tensor([-0.8987,  1.7180])    1      0   \n",
      "tensor([-0.5635,  0.6942])    1      0   \n",
      "tensor([ 0.2432, -2.4271])    0      0   \n",
      "tensor([-1.4543,  2.4676])    1      1   \n",
      "tensor([-6.8622,  4.9834])    1      1   \n",
      "tensor([-1.2291,  1.2807])    1      0   \n",
      "tensor([ 1.0200, -1.9224])    0      0   \n",
      "tensor([ 2.4445, -1.0249])    0      0   \n",
      "tensor([0.3060, 0.3347])      1      0   \n",
      "tensor([-0.5527,  0.2754])    1      0   \n",
      "tensor([ 3.4211, -5.8447])    0      0   \n",
      "tensor([-3.3386,  1.9456])    1      1   \n",
      "tensor([-0.5925,  1.7549])    1      0   \n",
      "tensor([ 1.5654, -2.4962])    0      0   \n",
      "tensor([0.2153, 0.2130])      0      0   \n",
      "tensor([ 0.5612, -0.3606])    0      0   \n",
      "tensor([1.0230, 0.3524])      0      0   \n",
      "tensor([ 0.7240, -2.2760])    0      0   \n",
      "tensor([ 0.6774, -0.8097])    0      0   \n",
      "tensor([-2.4865,  1.4914])    1      0   \n",
      "tensor([ 0.9123, -0.8004])    0      0   \n",
      "tensor([ 1.2685, -1.1795])    0      0   \n",
      "tensor([-1.8406,  2.3709])    1      1   \n",
      "tensor([-0.7126,  1.3024])    1      0   \n",
      "tensor([-0.5419,  0.8591])    1      0   \n",
      "tensor([-0.8015,  0.3891])    1      0   \n",
      "tensor([-0.7072,  2.2514])    1      0   \n",
      "tensor([0.0174, 0.7934])      1      0   \n",
      "tensor([ 1.4264, -0.9849])    0      0   \n",
      "tensor([-1.9061,  2.2291])    1      0   \n",
      "tensor([-0.9518,  1.5185])    1      1   \n",
      "tensor([ 1.1950, -0.4576])    0      0   \n",
      "tensor([-5.1975,  4.8585])    1      1   \n",
      "tensor([-0.5386,  1.9881])    1      0   \n",
      "tensor([-2.4115,  2.3257])    1      0   \n",
      "tensor([-1.2843,  2.4122])    1      1   \n",
      "tensor([ 2.0192, -2.1994])    0      0   \n",
      "tensor([1.1350, 0.0620])      0      0   \n",
      "tensor([-2.5279,  1.1956])    1      0   \n",
      "tensor([-0.8234,  1.2179])    1      0   \n",
      "tensor([ 0.1835, -0.9729])    0      0   \n",
      "tensor([-1.7074,  3.3906])    1      1   \n",
      "tensor([-3.9063,  3.8334])    1      1   \n",
      "tensor([-0.4233,  0.4662])    1      0   \n",
      "tensor([-1.8579,  1.4090])    1      1   \n",
      "tensor([0.6112, 0.7361])      1      0   \n",
      "tensor([-9.1106,  7.9712])    1      1   \n",
      "tensor([ 0.2877, -0.7476])    0      0   \n",
      "tensor([ 3.5009, -3.1515])    0      0   \n",
      "tensor([-0.2756, -0.3552])    0      0   \n",
      "tensor([ 1.0420, -0.9656])    0      0   \n",
      "tensor([-0.6804,  1.7136])    1      0   \n",
      "tensor([-4.3275,  0.2607])    1      1   \n",
      "tensor([ 1.4639, -2.6720])    0      0   \n",
      "tensor([0.6082, 0.0150])      0      0   \n",
      "tensor([-2.2730,  3.1536])    1      1   \n",
      "tensor([-0.0743, -0.3509])    0      0   \n",
      "tensor([-3.5590,  3.6957])    1      1   \n",
      "tensor([-0.5390,  0.4694])    1      0   \n",
      "tensor([-4.5726,  2.1639])    1      1   \n",
      "tensor([-5.4414,  2.7900])    1      1   \n",
      "tensor([-0.1955,  2.4223])    1      0   \n",
      "tensor([-0.7793,  0.8008])    1      0   \n",
      "tensor([ 0.2062, -0.0168])    0      0   \n",
      "tensor([-12.1057,   7.0742])    1      1   \n",
      "tensor([ 1.0145, -2.6840])    0      0   \n",
      "tensor([-0.8125,  1.1398])    1      0   \n",
      "tensor([ 3.6607, -3.0753])    0      0   \n",
      "tensor([ 1.0636, -1.2394])    0      0   \n",
      "tensor([-1.2799,  0.3935])    1      0   \n",
      "tensor([ 2.7611, -3.3846])    0      0   \n",
      "tensor([-0.1190,  1.6590])    1      0   \n",
      "tensor([ 2.7589, -1.0696])    0      0   \n",
      "tensor([-0.0255,  0.5398])    1      0   \n",
      "tensor([-1.1309,  1.6740])    1      0   \n",
      "tensor([ 0.3955, -0.8130])    0      0   \n",
      "tensor([-2.4140,  3.0631])    1      1   \n",
      "tensor([ 1.8175, -0.9083])    0      0   \n",
      "tensor([-8.2646,  5.0049])    1      1   \n",
      "tensor([-2.0553,  2.7651])    1      1   \n",
      "tensor([-0.7481,  1.6939])    1      0   \n",
      "tensor([ 3.1678, -3.7451])    0      0   \n",
      "tensor([ 0.6656, -0.5378])    0      0   \n",
      "tensor([ 3.5163, -1.8727])    0      0   \n",
      "tensor([-2.3303,  1.1859])    1      0   \n",
      "tensor([-4.8849,  3.4446])    1      0   \n",
      "tensor([-1.9345,  1.2522])    1      0   \n",
      "tensor([-1.8561,  1.6029])    1      0   \n",
      "tensor([-0.9791,  1.1909])    1      0   \n",
      "tensor([ 1.5766, -2.9321])    0      0   \n",
      "tensor([ 3.5745, -5.1681])    0      0   \n",
      "tensor([ 2.2168, -3.8473])    0      0   \n",
      "tensor([1.7024, 0.2956])      0      0   \n",
      "tensor([ 4.3723, -7.4719])    0      0   \n",
      "tensor([ 1.5158, -2.5734])    0      0   \n",
      "tensor([-0.6611,  1.7748])    1      0   \n",
      "tensor([ 2.9774, -4.1697])    0      0   \n",
      "tensor([-1.5138,  0.7156])    1      0   \n",
      "tensor([-0.0574, -0.4158])    0      0   \n",
      "tensor([ 3.3595, -1.5681])    0      0   \n",
      "tensor([ 3.9529, -1.3886])    0      0   \n",
      "tensor([-1.6745,  2.0445])    1      0   \n",
      "tensor([ 1.4097, -0.0839])    0      0   \n",
      "tensor([-3.1643,  2.6435])    1      0   \n",
      "tensor([ 2.0253, -3.8700])    0      0   \n",
      "tensor([-3.1383,  4.9056])    1      1   \n",
      "tensor([-8.8676,  5.0180])    1      1   \n",
      "tensor([-1.4572,  1.2070])    1      1   \n",
      "tensor([-3.7381,  3.3625])    1      1   \n",
      "tensor([-3.7108,  2.9151])    1      1   \n",
      "tensor([-2.6633,  6.5355])    1      1   \n",
      "tensor([ 1.3506, -3.7494])    0      0   \n",
      "\n",
      "226 out of 300 = 75.33% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 300\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
