{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].replace(['M', 'B'], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=30, h1=13, h2=15, h3 = 10, out_features=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # input layer -> 1 hidden -> 2 hidden -> output \n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.fc3 = nn.Linear(h2, h3)            # hidden layer\n",
    "        self.out = nn.Linear(h3, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the neuron input through its activation function to obtain the output of the neuron\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis',axis=1).values\n",
    "y = df['diagnosis'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "# y_train = F.one_hot(torch.LongTensor(y_train))  # not needed with Cross Entropy Loss\n",
    "# y_test = F.one_hot(torch.LongTensor(y_test))\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # CrossEntropy does not need one hot encoding\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 2.20097756\n",
      "epoch: 11  loss: 0.46095777\n",
      "epoch: 21  loss: 0.25409105\n",
      "epoch: 31  loss: 0.20364757\n",
      "epoch: 41  loss: 0.19536978\n",
      "epoch: 51  loss: 0.18292333\n",
      "epoch: 61  loss: 0.17422704\n",
      "epoch: 71  loss: 0.20319961\n",
      "epoch: 81  loss: 0.17763655\n",
      "epoch: 91  loss: 0.15645792\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 # number of runs through the training data\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad() #zero-grad to not accomulate the gradient over the epochs\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1520, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');\n",
    "print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21600157\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([-7.8742, -1.2721])              1\n",
      " 2. tensor([-1.3130, -4.6582])              0\n",
      " 3. tensor([-1.0213, -4.9825])              0\n",
      " 4. tensor([-2.9558, -5.5949])              0\n",
      " 5. tensor([-3.9474, -3.5512])              0\n",
      " 6. tensor([-4.0169, -3.9932])              0\n",
      " 7. tensor([-1.0438, -6.3037])              0\n",
      " 8. tensor([-0.8091, -5.7496])              0\n",
      " 9. tensor([-1.0149, -6.5501])              0\n",
      "10. tensor([-0.1179, -4.7702])              0\n",
      "11. tensor([-0.4787, -4.7233])              0\n",
      "12. tensor([-4.7310,  1.2649])              1\n",
      "13. tensor([-0.1160, -5.1227])              0\n",
      "14. tensor([-2.9937, -3.1223])              1\n",
      "15. tensor([-1.6158, -4.4075])              0\n",
      "16. tensor([-5.5938, -1.0443])              1\n",
      "17. tensor([-2.0081, -4.8242])              0\n",
      "18. tensor([-1.6239, -5.9195])              0\n",
      "19. tensor([-0.3896, -4.4534])              0\n",
      "20. tensor([-3.1768, -5.3305])              0\n",
      "21. tensor([-3.2055, -1.8226])              1\n",
      "22. tensor([-0.0618, -4.4015])              0\n",
      "23. tensor([-0.2269, -5.0390])              0\n",
      "24. tensor([-1.6044, -4.4876])              0\n",
      "25. tensor([-12.8737,   8.1815])            1\n",
      "26. tensor([-9.7501,  3.2209])              1\n",
      "27. tensor([-4.7478,  2.1822])              1\n",
      "28. tensor([-3.6482, -3.7988])              0\n",
      "29. tensor([-3.9677, -1.5852])              1\n",
      "30. tensor([-0.8007, -5.7381])              0\n",
      "31. tensor([-3.4881, -4.0569])              0\n",
      "32. tensor([-1.9342, -6.3366])              0\n",
      "33. tensor([-3.5075, -3.4542])              0\n",
      "34. tensor([-1.4837, -4.4949])              0\n",
      "35. tensor([-0.4720, -5.2714])              0\n",
      "36. tensor([-6.3289, -2.0333])              1\n",
      "37. tensor([-11.6447,   4.3232])            1\n",
      "38. tensor([-1.3880, -5.8266])              0\n",
      "39. tensor([-1.1731, -5.1566])              0\n",
      "40. tensor([-0.8561, -5.3245])              0\n",
      "41. tensor([-2.9195, -4.0931])              1\n",
      "42. tensor([-0.9913, -6.2980])              0\n",
      "43. tensor([-1.6493, -5.6306])              0\n",
      "44. tensor([-2.8757, -5.9000])              0\n",
      "45. tensor([-1.1259, -5.2115])              0\n",
      "46. tensor([-2.1557, -3.8599])              0\n",
      "47. tensor([-3.9330, -5.3790])              0\n",
      "48. tensor([-2.6507, -3.1113])              0\n",
      "49. tensor([-2.3567, -5.1822])              0\n",
      "50. tensor([-2.5735, -6.4759])              0\n",
      "51. tensor([-0.8525, -5.7960])              0\n",
      "52. tensor([-6.7323, -2.3929])              1\n",
      "53. tensor([-0.3945, -5.5888])              0\n",
      "54. tensor([-3.0746, -5.0470])              0\n",
      "55. tensor([-1.4361, -5.4532])              0\n",
      "56. tensor([-0.7045, -3.8128])              0\n",
      "57. tensor([-1.6532, -4.8987])              0\n",
      "58. tensor([-21.2612,  18.5997])            1\n",
      "59. tensor([-0.8264, -5.0247])              0\n",
      "60. tensor([-0.9496, -6.1873])              0\n",
      "61. tensor([-9.9520,  3.1476])              1\n",
      "62. tensor([-3.8529, -5.9219])              1\n",
      "63. tensor([-2.9287, -5.7798])              0\n",
      "64. tensor([-12.6946,  -1.2975])            1\n",
      "65. tensor([-2.1690, -4.7104])              0\n",
      "66. tensor([-0.7858, -5.8313])              0\n",
      "67. tensor([-2.7758, -4.6671])              0\n",
      "68. tensor([-3.3194, -4.7229])              0\n",
      "69. tensor([-2.4779, -7.1310])              1\n",
      "70. tensor([-10.8123,   2.7663])            1\n",
      "71. tensor([-1.2934, -5.8468])              0\n",
      "72. tensor([-2.0782, -6.7387])              0\n",
      "73. tensor([-0.1043, -4.9670])              0\n",
      "74. tensor([-12.4534,   6.2999])            1\n",
      "75. tensor([-8.2316,  0.8118])              1\n",
      "76. tensor([-3.5955, -2.7848])              1\n",
      "77. tensor([-9.9150,  2.8491])              1\n",
      "78. tensor([-4.4430, -2.1379])              1\n",
      "79. tensor([-11.2024,   8.8117])            1\n",
      "80. tensor([-1.4626, -7.1066])              0\n",
      "81. tensor([-7.7369, -2.9715])              1\n",
      "82. tensor([-1.3375, -5.1381])              0\n",
      "83. tensor([-2.6908, -5.6320])              0\n",
      "84. tensor([-3.1704, -5.3898])              1\n",
      "85. tensor([-1.5625, -4.5022])              0\n",
      "86. tensor([-8.6836, -2.7204])              1\n",
      "87. tensor([-3.3671, -4.2198])              1\n",
      "88. tensor([-6.5974, -4.7894])              1\n",
      "89. tensor([-4.7083, -2.1711])              1\n",
      "90. tensor([-0.7948, -5.0070])              0\n",
      "91. tensor([-0.3058, -3.0939])              0\n",
      "92. tensor([-9.2971,  2.1679])              1\n",
      "93. tensor([-5.6498,  1.0362])              1\n",
      "94. tensor([-2.3548, -5.2132])              0\n",
      "95. tensor([-3.9527, -1.4564])              1\n",
      "96. tensor([-4.5786, -2.5522])              1\n",
      "97. tensor([-2.5650, -4.4657])              0\n",
      "98. tensor([-10.9481,   8.1311])            1\n",
      "99. tensor([-2.4590, -3.8246])              0\n",
      "100. tensor([-1.3603, -5.6692])              0\n",
      "101. tensor([-4.2894, -5.1282])              1\n",
      "102. tensor([-1.4003, -6.4016])              0\n",
      "103. tensor([-1.7724, -4.2421])              1\n",
      "104. tensor([-0.2695, -6.2292])              0\n",
      "105. tensor([-1.0943, -4.6959])              0\n",
      "106. tensor([-19.8345,  16.1932])            1\n",
      "107. tensor([-1.8509, -4.1810])              0\n",
      "108. tensor([-7.1787, -0.6074])              1\n",
      "109. tensor([-2.2489, -3.6471])              0\n",
      "110. tensor([-13.8559,  13.1427])            1\n",
      "111. tensor([-2.5181, -4.2371])              0\n",
      "112. tensor([-13.1471,   6.1200])            1\n",
      "113. tensor([-3.0531, -6.5639])              0\n",
      "114. tensor([-8.7213,  1.7543])              1\n",
      "\n",
      "103 out of 114 = 90.35% correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38}  {y_test[i]}')\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
